{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data wrangling, preprocessing and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras import callbacks\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "# Importing libraries for building the neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAKE_NOISE_KerasBinaryClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Training the Keras Binary classifier.....\n",
      "Train on 352 samples, validate on 88 samples\n",
      "Epoch 1/1\n",
      "352/352 [==============================] - 0s 761us/step - loss: 0.5566 - acc: 0.7386 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Trained Model is Saved @  /Users/raghav/envPython3/experiments/sanity_beta_distribution\n",
      "1.0\n",
      "===================================\n",
      "AUC: 1.0\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class FakeNoiseNN:\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    def test_KerasBinaryClassifier(self,X_testPos,X_testNeg):\n",
    "        \n",
    "\n",
    "        X_test = np.concatenate((X_testPos,X_testNeg),axis=0)\n",
    "        X_testPosLabel = np.ones(len(X_testPos))\n",
    "        X_testNegLabel = np.zeros(len(X_testNeg))\n",
    "        y_test = np.concatenate((X_testPosLabel,X_testNegLabel),axis=0)\n",
    "        directory = os.getcwd()\n",
    "        pipe = joblib.load(os.path.join(directory, 'pipeline.pkl'))\n",
    "        model = models.load_model(os.path.join(directory, 'model.h5'))\n",
    "        pipe.steps.append(('nn', model))\n",
    "\n",
    "\n",
    "        y_pred_keras = pipe.predict_proba(X_test)[:, 0]\n",
    "        from sklearn.metrics import roc_curve\n",
    "        fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)\n",
    "        from sklearn.metrics import auc\n",
    "        auc_keras = auc(fpr_keras, tpr_keras)\n",
    "        print(auc_keras)\n",
    "        return auc_keras\n",
    "    \n",
    "    def train_KerasBinaryClassifier(self,X_train,y_train):\n",
    "\n",
    "        # Use Tenserflow backend\n",
    "        sess = tf.Session()\n",
    "        K.set_session(sess)\n",
    "\n",
    "        def model():\n",
    "            model = models.Sequential([\n",
    "                layers.Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
    "                layers.Dropout(0.5),\n",
    "                layers.Dense(1, activation='sigmoid')\n",
    "            ])\n",
    "            model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "            return model\n",
    "\n",
    "\n",
    "        early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=1, verbose=0, mode='auto')\n",
    "\n",
    "        pipe = pipeline.Pipeline([\n",
    "            ('rescale', preprocessing.StandardScaler()),\n",
    "            ('nn', KerasClassifier(build_fn=model, nb_epoch=10, batch_size=128,\n",
    "                                   validation_split=0.2, callbacks=[early_stopping]))\n",
    "        ])\n",
    "\n",
    "\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "        import os\n",
    "        directory = os.getcwd()\n",
    "        model_step = pipe.steps.pop(-1)[1]\n",
    "        joblib.dump(pipe, os.path.join(directory, 'pipeline.pkl'))\n",
    "        print(\"Trained Model is Saved @ \",directory)\n",
    "        models.save_model(model_step.model, os.path.join(directory, 'model.h5'))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_TestingData(self):\n",
    "\n",
    "        dataPath = './'\n",
    "        import tempfile\n",
    "        import pickle\n",
    "\n",
    "        with open(dataPath+'usps_data.pkl','rb') as fp:\n",
    "              loaded_data1 = pickle.load(fp, encoding='latin1')\n",
    "\n",
    "        labels = loaded_data1['target']\n",
    "        data = loaded_data1['data']\n",
    "        \n",
    "        ## Scale the data \n",
    "       \n",
    "  \n",
    "        print(scaler.fit(data))\n",
    "        StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "        data = scaler.transform(data)\n",
    "   \n",
    "        ## Select Ones\n",
    "        k_ones = np.where(labels == 2)\n",
    "        label_ones = labels[k_ones]\n",
    "        data_ones = data[k_ones]\n",
    "\n",
    "        k_sevens = np.where(labels == 8)\n",
    "        label_sevens = labels[k_sevens]\n",
    "        data_sevens = data[k_sevens]\n",
    "\n",
    "\n",
    "        data_ones = data_ones[220:440] \n",
    "        data_sevens =  np.random.uniform(0,1,(len(data_ones),256))\n",
    "        \n",
    "        label_ones      =  1*np.ones(len(data_ones))\n",
    "        label_sevens    =  np.zeros(len(data_sevens))\n",
    "        \n",
    "\n",
    "\n",
    "        return [data_ones,label_ones,data_sevens,label_sevens]\n",
    "    \n",
    "    \n",
    "    def get_FAKE_Noise_TrainingData(self,X):\n",
    "        \n",
    "        data_sevens =  np.random.uniform(0,1,(len(X),256))\n",
    "        label_sevens    =  np.zeros(len(data_sevens))\n",
    "        return [data_sevens,label_sevens]\n",
    "\n",
    "   \n",
    "    def get_TrainingData(self):\n",
    "        \n",
    "        dataPath = './'\n",
    "        import tempfile\n",
    "        import pickle\n",
    "       \n",
    "\n",
    "        with open(dataPath+'usps_data.pkl','rb') as fp:\n",
    "              loaded_data1 = pickle.load(fp, encoding='latin1')\n",
    "\n",
    "        labels = loaded_data1['target']\n",
    "        data = loaded_data1['data']\n",
    "        \n",
    "        ## Scale the data \n",
    "       \n",
    "        print(scaler.fit(data))\n",
    "        StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "        data = scaler.transform(data)\n",
    "   \n",
    "        ## Select Ones\n",
    "        k_ones = np.where(labels == 2)\n",
    "        label_ones = labels[k_ones]\n",
    "        data_ones = data[k_ones]\n",
    "\n",
    "        k_sevens = np.where(labels == 8)\n",
    "        label_sevens = labels[k_sevens]\n",
    "        data_sevens = data[k_sevens]\n",
    "\n",
    "\n",
    "        data_ones = data_ones[:220] \n",
    "        label_ones      =  1*np.ones(len(data_ones))\n",
    "       \n",
    "        return [data_ones,label_ones]\n",
    "    \n",
    "    \n",
    "    def fit(self,X):\n",
    "  \n",
    "        X_Neg,X_NegLabel = self.get_FAKE_Noise_TrainingData(X)\n",
    "        data = np.concatenate((X_Pos,X_Neg),axis=0)\n",
    "        label = np.concatenate((X_PosLabel,X_NegLabel),axis=0)\n",
    "        print(\"Training the Keras Binary classifier.....\")\n",
    "        self.train_KerasBinaryClassifier(data,label)\n",
    "        \n",
    "         \n",
    "    def predict(self,Xtest_Pos,Xtest_Neg):\n",
    "        result = self.test_KerasBinaryClassifier(Xtest_Pos,Xtest_Neg)\n",
    "        return result\n",
    "        \n",
    "        \n",
    "fakeNN = FakeNoiseNN()\n",
    "X_Pos,X_PosLabel = fakeNN.get_TrainingData()\n",
    "[Xtest_Pos,label_ones,Xtest_Neg,label_sevens]= fakeNN.get_TestingData()\n",
    "fakeNN.fit(X_Pos)\n",
    "res = fakeNN.predict(Xtest_Pos,Xtest_Neg)\n",
    "print(\"=\"*35)\n",
    "print(\"AUC:\",res)\n",
    "print(\"=\"*35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLEARN OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Training the OCSVM classifier.....\n",
      "===================================\n",
      "AUC: 1.0\n",
      "===================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class OCSVM:\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    \n",
    "    def test_OCSVM_Classifier(self,X_testPos,X_testNeg):\n",
    "        \n",
    "\n",
    "        X_test = np.concatenate((X_testPos,X_testNeg),axis=0)\n",
    "        X_testPosLabel = np.ones(len(X_testPos))\n",
    "        X_testNegLabel = np.zeros(len(X_testNeg))\n",
    "        y_test = np.concatenate((X_testPosLabel,X_testNegLabel),axis=0)\n",
    "        directory = os.getcwd()\n",
    "        pipe = joblib.load(os.path.join(directory, 'pipeline.pkl'))\n",
    "        model = models.load_model(os.path.join(directory, 'model.h5'))\n",
    "        pipe.steps.append(('nn', model))\n",
    "\n",
    "\n",
    "        y_pred_keras = pipe.predict_proba(X_test)[:, 0]\n",
    "        from sklearn.metrics import roc_curve\n",
    "        fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)\n",
    "        from sklearn.metrics import auc\n",
    "        auc_keras = auc(fpr_keras, tpr_keras)\n",
    "        print(auc_keras)\n",
    "        return auc_keras\n",
    "    \n",
    "    def train_OCSVM_Classifier(self,X_train,nu,kernel):\n",
    "        from sklearn import svm\n",
    "        ocSVM = svm.OneClassSVM(nu = nu, kernel = kernel)\n",
    "        ocSVM.fit(X_train) \n",
    "\n",
    "        return ocSVM\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_TestingData(self):\n",
    "\n",
    "        dataPath = './'\n",
    "        import tempfile\n",
    "        import pickle\n",
    "\n",
    "        with open(dataPath+'usps_data.pkl','rb') as fp:\n",
    "              loaded_data1 = pickle.load(fp, encoding='latin1')\n",
    "\n",
    "        labels = loaded_data1['target']\n",
    "        data = loaded_data1['data']\n",
    "        \n",
    "        ## Scale the data \n",
    "       \n",
    "  \n",
    "        print(scaler.fit(data))\n",
    "        StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "        data = scaler.transform(data)\n",
    "   \n",
    "        ## Select Ones\n",
    "        k_ones = np.where(labels == 2)\n",
    "        label_ones = labels[k_ones]\n",
    "        data_ones = data[k_ones]\n",
    "\n",
    "        k_sevens = np.where(labels == 8)\n",
    "        label_sevens = labels[k_sevens]\n",
    "        data_sevens = data[k_sevens]\n",
    "\n",
    "\n",
    "        data_ones = data_ones[220:440] \n",
    "        data_sevens = data_sevens[:11]\n",
    "        # data_sevens =  np.random.uniform(0,1,(len(data_ones),256))\n",
    "        \n",
    "        label_ones      =  1*np.ones(len(data_ones))\n",
    "        label_sevens    =  np.zeros(len(data_sevens))\n",
    "        \n",
    "\n",
    "\n",
    "        return [data_ones,label_ones,data_sevens,label_sevens]\n",
    "    \n",
    "\n",
    "        \n",
    "        data_sevens =  np.random.uniform(0,1,(len(X),256))\n",
    "        label_sevens    =  np.zeros(len(data_sevens))\n",
    "        return [data_sevens,label_sevens]\n",
    "\n",
    "   \n",
    "    def get_TrainingData(self):\n",
    "        \n",
    "        dataPath = './'\n",
    "        import tempfile\n",
    "        import pickle\n",
    "       \n",
    "\n",
    "        with open(dataPath+'usps_data.pkl','rb') as fp:\n",
    "              loaded_data1 = pickle.load(fp, encoding='latin1')\n",
    "\n",
    "        labels = loaded_data1['target']\n",
    "        data = loaded_data1['data']\n",
    "        \n",
    "        ## Scale the data \n",
    "       \n",
    "        print(scaler.fit(data))\n",
    "        StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "        data = scaler.transform(data)\n",
    "   \n",
    "        ## Select Ones\n",
    "        k_ones = np.where(labels == 2)\n",
    "        label_ones = labels[k_ones]\n",
    "        data_ones = data[k_ones]\n",
    "\n",
    "        k_sevens = np.where(labels == 8)\n",
    "        label_sevens = labels[k_sevens]\n",
    "        data_sevens = data[k_sevens]\n",
    "\n",
    "\n",
    "        data_ones = data_ones[:220] \n",
    "        label_ones      =  1*np.ones(len(data_ones))\n",
    "       \n",
    "        return [data_ones,label_ones]\n",
    "    \n",
    "    \n",
    "    def fit(self,X,nu,kernel):\n",
    "  \n",
    "        print(\"Training the OCSVM classifier.....\")\n",
    "        clf = self.train_OCSVM_Classifier(X,nu,kernel)\n",
    "\n",
    "        return clf\n",
    "\n",
    "    \n",
    "    def compute_au_roc(self,y_true, df_score):\n",
    "        y_scores_pos = df_score[0]\n",
    "        y_scores_neg = df_score[1]\n",
    "        y_score = np.concatenate((y_scores_pos, y_scores_neg))\n",
    "        \n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        roc_score = roc_auc_score(y_true, y_score)\n",
    " \n",
    "        return roc_score\n",
    "         \n",
    "         \n",
    "    def predict(self,clf,Xtest_Pos,Xtest_Neg):\n",
    "        decisionScore_POS = clf.decision_function(Xtest_Pos)\n",
    "        decisionScore_Neg = clf.decision_function(Xtest_Neg)\n",
    "        df_score = [ decisionScore_POS, decisionScore_Neg ]\n",
    "        ## y_true\n",
    "        y_true_pos = np.ones(Xtest_Pos.shape[0])\n",
    "        y_true_neg = np.zeros(Xtest_Neg.shape[0])\n",
    "        y_true = np.concatenate((y_true_pos, y_true_neg))\n",
    "        \n",
    "        plt.hist(decisionScore_POS, bins = 25, label = 'Normal');\n",
    "        plt.hist(decisionScore_Neg, bins = 25, label = 'Anomaly');\n",
    "        plt.legend(loc = 'upper right');\n",
    "        plt.title('OC-SVM Normalised Decision Score');\n",
    "\n",
    "        result = self.compute_au_roc(y_true,df_score)\n",
    "        return result\n",
    "        \n",
    "        \n",
    "ocsvm = OCSVM()\n",
    "X_Pos,X_PosLabel = ocsvm.get_TrainingData()\n",
    "[Xtest_Pos,label_ones,Xtest_Neg,label_sevens]= ocsvm.get_TestingData()\n",
    "nu= 0.04\n",
    "kernel = 'rbf'\n",
    "clf = ocsvm.fit(X_Pos,nu,kernel)\n",
    "res = ocsvm.predict(clf,Xtest_Pos,Xtest_Neg)\n",
    "print(\"=\"*35)\n",
    "print(\"AUC:\",res)\n",
    "print(\"=\"*35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OC-NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Training the OCNN classifier.....\n",
      "Training OC-NN started for epochs:  10\n",
      "================================\n",
      "Epoch = 1, r = -566.405496\n",
      "================================\n",
      "Total Cost:  18809752.0\n",
      "Training Time taken, 0.17137885093688965\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -566.4054956054688\n",
      "================================\n",
      "Epoch = 2, r = -565.850132\n",
      "================================\n",
      "Total Cost:  18769572.0\n",
      "Training Time taken, 0.302016019821167\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -565.8501318359375\n",
      "================================\n",
      "Epoch = 3, r = -565.294673\n",
      "================================\n",
      "Total Cost:  18729436.0\n",
      "Training Time taken, 0.42342495918273926\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -565.2946728515625\n",
      "================================\n",
      "Epoch = 4, r = -564.739231\n",
      "================================\n",
      "Total Cost:  18689348.0\n",
      "Training Time taken, 0.5500638484954834\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -564.7392309570313\n",
      "================================\n",
      "Epoch = 5, r = -564.183911\n",
      "================================\n",
      "Total Cost:  18649310.0\n",
      "Training Time taken, 0.6907048225402832\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -564.1839111328125\n",
      "================================\n",
      "Epoch = 6, r = -563.628699\n",
      "================================\n",
      "Total Cost:  18609318.0\n",
      "Training Time taken, 0.8452527523040771\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -563.6286987304687\n",
      "================================\n",
      "Epoch = 7, r = -563.073423\n",
      "================================\n",
      "Total Cost:  18569374.0\n",
      "Training Time taken, 1.026587963104248\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -563.0734228515626\n",
      "================================\n",
      "Epoch = 8, r = -562.518223\n",
      "================================\n",
      "Total Cost:  18529482.0\n",
      "Training Time taken, 1.2149817943572998\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -562.5182226562499\n",
      "================================\n",
      "Epoch = 9, r = -561.963223\n",
      "================================\n",
      "Total Cost:  18489644.0\n",
      "Training Time taken, 1.4243488311767578\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -561.96322265625\n",
      "================================\n",
      "Epoch = 10, r = -561.422817\n",
      "================================\n",
      "Total Cost:  18449850.0\n",
      "Training Time taken, 1.6428818702697754\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -561.4228173828125\n",
      "===================================\n",
      "AUC: 0.35082644628099174\n",
      "===================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class OCNN:\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import numpy  as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as srn\n",
    "  \n",
    "    \n",
    "\n",
    "    results = \"./sanity_results/\"\n",
    "    decision_scorePath = \"./scores/\"\n",
    "    df_usps_scores  = {}\n",
    "    activations = [\"Linear\",\"Sigmoid\"]\n",
    "    methods = [\"Linear\",\"RBF\"]\n",
    "    path = \"./scores/\"\n",
    "    model_weights = \"./model_weights/\"\n",
    "   \n",
    "    nu = 0.1\n",
    "    scaler = StandardScaler()\n",
    "    h_size = 200\n",
    "    \n",
    "\n",
    "    def write_Scores2Csv(self,train, trainscore, test, testscore,filename):\n",
    "\n",
    "            data = np.concatenate((train, test))\n",
    "            score= np.concatenate((trainscore,testscore))\n",
    "            data = data.tolist()\n",
    "            score = score.tolist()\n",
    "            with open(filename, 'a') as myfile:\n",
    "                wr = csv.writer(myfile)\n",
    "                wr.writerow((\"x\", \"score\"))\n",
    "            for row in range(0,len(data)):\n",
    "                with open(filename,\n",
    "                        'a') as myfile:\n",
    "                    wr = csv.writer(myfile)\n",
    "\n",
    "                    wr.writerow((\" \".join(str(x) for x in data[row]), \" \".join(str(x) for x in score[row])))\n",
    "    def write_decisionScores2Csv(self,path, filename, positiveScores, negativeScores):\n",
    "\n",
    "            newfilePath = path+filename\n",
    "            print(\"Writing file to \", path+filename)\n",
    "            poslist = positiveScores.tolist()\n",
    "            neglist = negativeScores.tolist()\n",
    "\n",
    "            # rows = zip(poslist, neglist)\n",
    "            d = [poslist, neglist]\n",
    "            export_data = izip_longest(*d, fillvalue='')\n",
    "            with open(newfilePath, 'w') as myfile:\n",
    "                wr = csv.writer(myfile)\n",
    "                wr.writerow((\"Normal\", \"Anomaly\"))\n",
    "                wr.writerows(export_data)\n",
    "            myfile.close()\n",
    "\n",
    "            return\n",
    "\n",
    "    def train_OCNN_Classifier(self,X_train,nu,activation,epochs):\n",
    "\n",
    "        RANDOM_SEED = 42\n",
    "        tf.reset_default_graph()\n",
    "        train_X = X_train\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "        outfile = \"./model_weights/\"\n",
    "        oCSVMweights = \"./weights/\"\n",
    "        import time\n",
    "\n",
    "        # Layer's sizes\n",
    "        x_size = train_X.shape[1]   # Number of input nodes: 4 features and 1 bias\n",
    "        h_size = self.h_size             # Number of hidden nodes\n",
    "        y_size = 1   # Number of outcomes (3 iris flowers)\n",
    "        D = x_size\n",
    "        K = h_size\n",
    "        theta = np.random.normal(0, 1, K + K*D + 1)\n",
    "        rvalue = np.random.normal(0,1,(len(train_X),y_size))\n",
    "        g   = lambda x : (1/np.sqrt(h_size) )*tf.cos(x/0.02)\n",
    "\n",
    "        def init_weights(shape):\n",
    "            \"\"\" Weight initialization \"\"\"\n",
    "            weights = tf.random_normal(shape,mean=0, stddev=0.5)\n",
    "            return tf.Variable(weights,trainable=False)\n",
    "\n",
    "            def forwardprop(X, w_1, w_2):\n",
    "                \"\"\"\n",
    "                Forward-propagation.\n",
    "                IMPORTANT: yhat is not softmax since TensorFlow's softmax_cross_entropy_with_logits() does that internally.\n",
    "                \"\"\"\n",
    "                X = tf.cast(X, tf.float32)\n",
    "                w_1 = tf.cast(w_1, tf.float32)\n",
    "                w_2 = tf.cast(w_2, tf.float32)\n",
    "                h    = tf.nn.sigmoid(tf.matmul(X, w_1))  # The \\sigma function\n",
    "                yhat = tf.matmul(h, w_2)  # The \\varphi function\n",
    "                return yhat\n",
    "        \n",
    "      \n",
    "        \n",
    "        def nnScore(X, w, V, g,bias1,bias2):\n",
    "            X = tf.cast(X, tf.float32)\n",
    "            w = tf.cast(w, tf.float32)\n",
    "            V = tf.cast(V, tf.float32)\n",
    "            y_hat =tf.matmul(g((tf.matmul(X, w)+bias1)), V) +bias2\n",
    "\n",
    "            return y_hat\n",
    "        \n",
    "        def relu(x):\n",
    "            y = x\n",
    "            y[y < 0] = 0\n",
    "            return y\n",
    "        \n",
    "        # For testing the algorithm\n",
    "        def compute_LossValue(X, nu, w1, w2, g, r,bias1,bias2):\n",
    "            w = w1\n",
    "            V = w2\n",
    "\n",
    "            X = tf.cast(X, tf.float32)\n",
    "            w = tf.cast(w1, tf.float32)\n",
    "            V = tf.cast(w2, tf.float32)\n",
    "            term1 = 0.5 * tf.reduce_sum(tf.square(w))\n",
    "            term2 = 0.5 * tf.reduce_sum(tf.square(V))\n",
    "\n",
    "\n",
    "            \n",
    "            term3 = 1 / nu * tf.reduce_mean(tf.nn.relu(r - nnScore(X, w, V, g,bias1,bias2)))\n",
    "            term4 = -r\n",
    "            \n",
    "            y_hat = nnScore(X, w, V, g,bias1,bias2)\n",
    "            \n",
    "            totalCost = term1 + term2 + term3 + term4\n",
    "                \n",
    "            loss=   [term1,term2,term3,term4,totalCost,y_hat]\n",
    "            \n",
    "            return loss\n",
    "            \n",
    "            \n",
    "        def ocnn_obj(theta, X, nu, w1, w2, g,r,bias1,bias2):\n",
    "\n",
    "            w = w1\n",
    "            V = w2\n",
    "     \n",
    "            X = tf.cast(X, tf.float32)\n",
    "            w = tf.cast(w1, tf.float32)\n",
    "            V = tf.cast(w2, tf.float32)\n",
    "\n",
    "\n",
    "            term1 = 0.5  * tf.reduce_sum(w**2)\n",
    "            term2 = 0.5  * tf.reduce_sum(V**2)\n",
    "            term3 = 1/nu * tf.reduce_mean(tf.nn.relu(r - nnScore(X, w, V, g,bias1,bias2)))\n",
    "            term4 = -r\n",
    "\n",
    "            return term1 + term2 + term3 + term4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Symbols\n",
    "        X = tf.placeholder(\"float32\", shape=[None, x_size])\n",
    "\n",
    "        r = tf.get_variable(\"r\", dtype=tf.float32,shape=())\n",
    "\n",
    "        # Weight initializations\n",
    "        w_1 = init_weights((x_size, h_size))\n",
    "           \n",
    "        weights = tf.random_normal((h_size, y_size),mean=0, stddev=0.1)\n",
    "           \n",
    "        ocsvm_wt = np.load(oCSVMweights+\"ocsvm_wt.npy\")\n",
    "        w_2 =tf.get_variable(\"tf_var_initialized_ocsvm\",\n",
    "                                initializer=ocsvm_wt)\n",
    "            \n",
    "        bias1 = tf.Variable(initial_value=[[1.0]], dtype=tf.float32,trainable=False)\n",
    "        bias2 = tf.Variable(initial_value=[[0.0]], dtype=tf.float32,trainable=False)\n",
    "\n",
    "\n",
    "        cost    = ocnn_obj(theta, X, nu, w_1, w_2, g,r,bias1,bias2)\n",
    "        #updates = tf.train.GradientDescentOptimizer(0.0001).minimize(cost)\n",
    "        updates = tf.train.AdamOptimizer(4.7 * 1e-1).minimize(cost)\n",
    "\n",
    "        # Run SGD\n",
    "        sess = tf.Session()\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        rvalue = 0.1\n",
    "        start_time = time.time()\n",
    "        print(\"Training OC-NN started for epochs: \",epochs)\n",
    "        for epoch in range(epochs):\n",
    "                    # Train with each example\n",
    "            sess.run(updates, feed_dict={X: train_X})\n",
    "                        \n",
    "                    \n",
    "            with sess.as_default():\n",
    "                svalue = nnScore(train_X, w_1, w_2, g,bias1,bias2)  \n",
    "                rval = svalue.eval()\n",
    "                rvalue = np.percentile(rval,q=100*nu)\n",
    "                            \n",
    "\n",
    "                costvalue = compute_LossValue(train_X, nu, w_1, w_2, g, rvalue,bias1,bias2)\n",
    "                term1 = costvalue[0].eval()\n",
    "                term2 = costvalue[1].eval()\n",
    "                term3 = costvalue[2].eval()\n",
    "                term4 = costvalue[3]\n",
    "                term5 = costvalue[4].eval()\n",
    "                yval = costvalue[5].eval()\n",
    "                print (\"================================\")\n",
    "                print (\"Epoch = %d, r = %f\"\n",
    "                        % (epoch + 1,rvalue))\n",
    "                print (\"================================\")\n",
    "                print (\"Total Cost: \",np.mean(term5))\n",
    "                        \n",
    "                import time\n",
    "                trainTime = time.time() - start_time\n",
    "                print(\"Training Time taken,\",trainTime)\n",
    "          \n",
    "            \n",
    "            \n",
    "                with sess.as_default():\n",
    "                    np_w_1= w_1.eval()\n",
    "                    np_w_2= w_2.eval()\n",
    "                    np_bias1= bias1.eval()\n",
    "                    np_bias2= bias2.eval()\n",
    "            \n",
    "                rstar =rvalue\n",
    "#             sess.close()\n",
    "#             print(\"Session Closed!!!\")\n",
    "\n",
    "            # save the w_1 and bias1 to numpy array\n",
    "            print(\"Saving the trained Model weights ... @\",outfile)\n",
    "            print(\"The optimized value of r found is\",rstar)\n",
    "            np.save(outfile+\"w_1\", np_w_1)\n",
    "            np.save(outfile+\"w_2\", np_w_2)\n",
    "            np.save(outfile+\"bias1\",np_bias1)\n",
    "            np.save(outfile+\"bias2\",np_bias2)\n",
    "\n",
    "   \n",
    "    def get_TestingData(self):\n",
    "\n",
    "        dataPath = './'\n",
    "        import tempfile\n",
    "        import pickle\n",
    "\n",
    "        with open(dataPath+'usps_data.pkl','rb') as fp:\n",
    "              loaded_data1 = pickle.load(fp, encoding='latin1')\n",
    "\n",
    "        labels = loaded_data1['target']\n",
    "        data = loaded_data1['data']\n",
    "        \n",
    "        ## Scale the data \n",
    "       \n",
    "  \n",
    "        print(scaler.fit(data))\n",
    "        StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "        data = scaler.transform(data)\n",
    "   \n",
    "        ## Select Ones\n",
    "        k_ones = np.where(labels == 2)\n",
    "        label_ones = labels[k_ones]\n",
    "        data_ones = data[k_ones]\n",
    "\n",
    "        k_sevens = np.where(labels == 8)\n",
    "        label_sevens = labels[k_sevens]\n",
    "        data_sevens = data[k_sevens]\n",
    "\n",
    "\n",
    "        data_ones = data_ones[220:440] \n",
    "        data_sevens = data_sevens[0:11]\n",
    "        # data_sevens =  np.random.uniform(0,1,(len(data_ones),256))\n",
    "        \n",
    "        label_ones      =  1*np.ones(len(data_ones))\n",
    "        label_sevens    =  np.zeros(len(data_sevens))\n",
    "        \n",
    "\n",
    "\n",
    "        return [data_ones,label_ones,data_sevens,label_sevens]\n",
    "    \n",
    "\n",
    "        \n",
    "        data_sevens =  np.random.uniform(0,1,(len(X),256))\n",
    "        label_sevens    =  np.zeros(len(data_sevens))\n",
    "        return [data_sevens,label_sevens]\n",
    "  \n",
    "    def get_TrainingData(self):\n",
    "        \n",
    "        dataPath = './'\n",
    "        import tempfile\n",
    "        import pickle\n",
    "       \n",
    "\n",
    "        with open(dataPath+'usps_data.pkl','rb') as fp:\n",
    "              loaded_data1 = pickle.load(fp, encoding='latin1')\n",
    "\n",
    "        labels = loaded_data1['target']\n",
    "        data = loaded_data1['data']\n",
    "        \n",
    "        ## Scale the data \n",
    "       \n",
    "        print(scaler.fit(data))\n",
    "        StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "        data = scaler.transform(data)\n",
    "   \n",
    "        ## Select Ones\n",
    "        k_ones = np.where(labels == 2)\n",
    "        label_ones = labels[k_ones]\n",
    "        data_ones = data[k_ones]\n",
    "\n",
    "        k_sevens = np.where(labels == 8)\n",
    "        label_sevens = labels[k_sevens]\n",
    "        data_sevens = data[k_sevens]\n",
    "\n",
    "\n",
    "        data_ones = data_ones[:220] \n",
    "        label_ones      =  1*np.ones(len(data_ones))\n",
    "       \n",
    "        return [data_ones,label_ones]\n",
    "     \n",
    "    def fit(self,X,nu,activation,epochs):\n",
    "  \n",
    "        print(\"Training the OCNN classifier.....\")\n",
    "        self.train_OCNN_Classifier(X,nu,activation,epochs)\n",
    "\n",
    "        return   \n",
    "    \n",
    "    def compute_au_roc(self,y_true, df_score):\n",
    "        y_scores_pos = df_score[0]\n",
    "        y_scores_neg = df_score[1]\n",
    "        y_score = np.concatenate((y_scores_pos, y_scores_neg))\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        roc_score = roc_auc_score(y_true, y_score)\n",
    " \n",
    "        return roc_score\n",
    "    \n",
    "    def decision_function(self,X, w_1, w_2, g,bias1,bias2):   \n",
    "        score =np.matmul(g((np.matmul(X, w_1)+bias1)), w_2) +bias2\n",
    "        return score\n",
    "\n",
    "    def predict(self,Xtest_Pos,Xtest_Neg):\n",
    "        \n",
    "        ## Load the saved model and compute the decision score\n",
    "        model_weights = \"./model_weights/\"\n",
    "        w_1 = np.load(model_weights+\"/w_1.npy\")\n",
    "        w_2 = np.load(model_weights+\"/w_2.npy\")\n",
    "        bias1 = np.load(model_weights+\"/bias1.npy\")\n",
    "        bias2 = np.load(model_weights+\"/bias2.npy\")\n",
    "        \n",
    "        \n",
    "        g   = lambda x : (1/np.sqrt(self.h_size) )*np.cos(x/0.02)\n",
    "\n",
    "        decisionScore_POS= self.decision_function(Xtest_Pos, w_1, w_2, g,bias1,bias2)\n",
    "        decisionScore_Neg = self.decision_function(Xtest_Neg, w_1, w_2, g,bias1,bias2)\n",
    "   \n",
    "        df_score = [decisionScore_POS, decisionScore_Neg]\n",
    "        \n",
    "        ## y_true\n",
    "        y_true_pos = np.ones(Xtest_Pos.shape[0])\n",
    "        y_true_neg = np.zeros(Xtest_Neg.shape[0])\n",
    "        y_true = np.concatenate((y_true_pos, y_true_neg))\n",
    "\n",
    "        plt.hist(decisionScore_POS, bins = 25, label = 'Normal')\n",
    "        plt.hist(decisionScore_Neg, bins = 25, label = 'Anomaly')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        plt.title('OC-NN Normalised Decision Score')\n",
    "\n",
    "        result = self.compute_au_roc(y_true,df_score)\n",
    "        return result\n",
    "        \n",
    "\n",
    "\n",
    "## Instantiate the object and call the function\n",
    "ocnn = OCNN()\n",
    "X_Pos,X_PosLabel = ocnn.get_TrainingData()\n",
    "[Xtest_Pos,label_ones,Xtest_Neg,label_sevens]= ocnn.get_TestingData()\n",
    "nu= 0.04\n",
    "activation = 'sigmoid'\n",
    "epochs = 10\n",
    "ocnn.fit(X_Pos,nu,activation,epochs)\n",
    "res = ocnn.predict(Xtest_Pos,Xtest_Neg)\n",
    "print(\"=\"*35)\n",
    "print(\"AUC:\",res)\n",
    "print(\"=\"*35)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
