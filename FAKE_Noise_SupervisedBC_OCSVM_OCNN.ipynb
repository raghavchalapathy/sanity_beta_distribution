{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data wrangling, preprocessing and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras import callbacks\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "# Importing libraries for building the neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAKE_NOISE_KerasBinaryClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Training the Keras Binary classifier.....\n",
      "Train on 352 samples, validate on 88 samples\n",
      "Epoch 1/1\n",
      "352/352 [==============================] - 0s 761us/step - loss: 0.5566 - acc: 0.7386 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Trained Model is Saved @  /Users/raghav/envPython3/experiments/sanity_beta_distribution\n",
      "1.0\n",
      "===================================\n",
      "AUC: 1.0\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class FakeNoiseNN:\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    def test_KerasBinaryClassifier(self,X_testPos,X_testNeg):\n",
    "        \n",
    "\n",
    "        X_test = np.concatenate((X_testPos,X_testNeg),axis=0)\n",
    "        X_testPosLabel = np.ones(len(X_testPos))\n",
    "        X_testNegLabel = np.zeros(len(X_testNeg))\n",
    "        y_test = np.concatenate((X_testPosLabel,X_testNegLabel),axis=0)\n",
    "        directory = os.getcwd()\n",
    "        pipe = joblib.load(os.path.join(directory, 'pipeline.pkl'))\n",
    "        model = models.load_model(os.path.join(directory, 'model.h5'))\n",
    "        pipe.steps.append(('nn', model))\n",
    "\n",
    "\n",
    "        y_pred_keras = pipe.predict_proba(X_test)[:, 0]\n",
    "        from sklearn.metrics import roc_curve\n",
    "        fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)\n",
    "        from sklearn.metrics import auc\n",
    "        auc_keras = auc(fpr_keras, tpr_keras)\n",
    "        print(auc_keras)\n",
    "        return auc_keras\n",
    "    \n",
    "    def train_KerasBinaryClassifier(self,X_train,y_train):\n",
    "\n",
    "        # Use Tenserflow backend\n",
    "        sess = tf.Session()\n",
    "        K.set_session(sess)\n",
    "\n",
    "        def model():\n",
    "            model = models.Sequential([\n",
    "                layers.Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
    "                layers.Dropout(0.5),\n",
    "                layers.Dense(1, activation='sigmoid')\n",
    "            ])\n",
    "            model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "            return model\n",
    "\n",
    "\n",
    "        early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=1, verbose=0, mode='auto')\n",
    "\n",
    "        pipe = pipeline.Pipeline([\n",
    "            ('rescale', preprocessing.StandardScaler()),\n",
    "            ('nn', KerasClassifier(build_fn=model, nb_epoch=10, batch_size=128,\n",
    "                                   validation_split=0.2, callbacks=[early_stopping]))\n",
    "        ])\n",
    "\n",
    "\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "        import os\n",
    "        directory = os.getcwd()\n",
    "        model_step = pipe.steps.pop(-1)[1]\n",
    "        joblib.dump(pipe, os.path.join(directory, 'pipeline.pkl'))\n",
    "        print(\"Trained Model is Saved @ \",directory)\n",
    "        models.save_model(model_step.model, os.path.join(directory, 'model.h5'))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_TestingData(self):\n",
    "\n",
    "        dataPath = './'\n",
    "        import tempfile\n",
    "        import pickle\n",
    "\n",
    "        with open(dataPath+'usps_data.pkl','rb') as fp:\n",
    "              loaded_data1 = pickle.load(fp, encoding='latin1')\n",
    "\n",
    "        labels = loaded_data1['target']\n",
    "        data = loaded_data1['data']\n",
    "        \n",
    "        ## Scale the data \n",
    "       \n",
    "  \n",
    "        print(scaler.fit(data))\n",
    "        StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "        data = scaler.transform(data)\n",
    "   \n",
    "        ## Select Ones\n",
    "        k_ones = np.where(labels == 2)\n",
    "        label_ones = labels[k_ones]\n",
    "        data_ones = data[k_ones]\n",
    "\n",
    "        k_sevens = np.where(labels == 8)\n",
    "        label_sevens = labels[k_sevens]\n",
    "        data_sevens = data[k_sevens]\n",
    "\n",
    "\n",
    "        data_ones = data_ones[220:440] \n",
    "        data_sevens =  np.random.uniform(0,1,(len(data_ones),256))\n",
    "        \n",
    "        label_ones      =  1*np.ones(len(data_ones))\n",
    "        label_sevens    =  np.zeros(len(data_sevens))\n",
    "        \n",
    "\n",
    "\n",
    "        return [data_ones,label_ones,data_sevens,label_sevens]\n",
    "    \n",
    "    \n",
    "    def get_FAKE_Noise_TrainingData(self,X):\n",
    "        \n",
    "        data_sevens =  np.random.uniform(0,1,(len(X),256))\n",
    "        label_sevens    =  np.zeros(len(data_sevens))\n",
    "        return [data_sevens,label_sevens]\n",
    "\n",
    "   \n",
    "    def get_TrainingData(self):\n",
    "        \n",
    "        dataPath = './'\n",
    "        import tempfile\n",
    "        import pickle\n",
    "       \n",
    "\n",
    "        with open(dataPath+'usps_data.pkl','rb') as fp:\n",
    "              loaded_data1 = pickle.load(fp, encoding='latin1')\n",
    "\n",
    "        labels = loaded_data1['target']\n",
    "        data = loaded_data1['data']\n",
    "        \n",
    "        ## Scale the data \n",
    "       \n",
    "        print(scaler.fit(data))\n",
    "        StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "        data = scaler.transform(data)\n",
    "   \n",
    "        ## Select Ones\n",
    "        k_ones = np.where(labels == 2)\n",
    "        label_ones = labels[k_ones]\n",
    "        data_ones = data[k_ones]\n",
    "\n",
    "        k_sevens = np.where(labels == 8)\n",
    "        label_sevens = labels[k_sevens]\n",
    "        data_sevens = data[k_sevens]\n",
    "\n",
    "\n",
    "        data_ones = data_ones[:220] \n",
    "        label_ones      =  1*np.ones(len(data_ones))\n",
    "       \n",
    "        return [data_ones,label_ones]\n",
    "    \n",
    "    \n",
    "    def fit(self,X):\n",
    "  \n",
    "        X_Neg,X_NegLabel = self.get_FAKE_Noise_TrainingData(X)\n",
    "        data = np.concatenate((X_Pos,X_Neg),axis=0)\n",
    "        label = np.concatenate((X_PosLabel,X_NegLabel),axis=0)\n",
    "        print(\"Training the Keras Binary classifier.....\")\n",
    "        self.train_KerasBinaryClassifier(data,label)\n",
    "        \n",
    "         \n",
    "    def predict(self,Xtest_Pos,Xtest_Neg):\n",
    "        result = self.test_KerasBinaryClassifier(Xtest_Pos,Xtest_Neg)\n",
    "        return result\n",
    "        \n",
    "        \n",
    "fakeNN = FakeNoiseNN()\n",
    "X_Pos,X_PosLabel = fakeNN.get_TrainingData()\n",
    "[Xtest_Pos,label_ones,Xtest_Neg,label_sevens]= fakeNN.get_TestingData()\n",
    "fakeNN.fit(X_Pos)\n",
    "res = fakeNN.predict(Xtest_Pos,Xtest_Neg)\n",
    "print(\"=\"*35)\n",
    "print(\"AUC:\",res)\n",
    "print(\"=\"*35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLEARN OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Training the OCSVM classifier.....\n",
      "===================================\n",
      "AUC: 1.0\n",
      "===================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class OCSVM:\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    \n",
    "    def test_OCSVM_Classifier(self,X_testPos,X_testNeg):\n",
    "        \n",
    "\n",
    "        X_test = np.concatenate((X_testPos,X_testNeg),axis=0)\n",
    "        X_testPosLabel = np.ones(len(X_testPos))\n",
    "        X_testNegLabel = np.zeros(len(X_testNeg))\n",
    "        y_test = np.concatenate((X_testPosLabel,X_testNegLabel),axis=0)\n",
    "        directory = os.getcwd()\n",
    "        pipe = joblib.load(os.path.join(directory, 'pipeline.pkl'))\n",
    "        model = models.load_model(os.path.join(directory, 'model.h5'))\n",
    "        pipe.steps.append(('nn', model))\n",
    "\n",
    "\n",
    "        y_pred_keras = pipe.predict_proba(X_test)[:, 0]\n",
    "        from sklearn.metrics import roc_curve\n",
    "        fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)\n",
    "        from sklearn.metrics import auc\n",
    "        auc_keras = auc(fpr_keras, tpr_keras)\n",
    "        print(auc_keras)\n",
    "        return auc_keras\n",
    "    \n",
    "    def train_OCSVM_Classifier(self,X_train,nu,kernel):\n",
    "        from sklearn import svm\n",
    "        ocSVM = svm.OneClassSVM(nu = nu, kernel = kernel)\n",
    "        ocSVM.fit(X_train) \n",
    "\n",
    "        return ocSVM\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_TestingData(self):\n",
    "\n",
    "        dataPath = './'\n",
    "        import tempfile\n",
    "        import pickle\n",
    "\n",
    "        with open(dataPath+'usps_data.pkl','rb') as fp:\n",
    "              loaded_data1 = pickle.load(fp, encoding='latin1')\n",
    "\n",
    "        labels = loaded_data1['target']\n",
    "        data = loaded_data1['data']\n",
    "        \n",
    "        ## Scale the data \n",
    "       \n",
    "  \n",
    "        print(scaler.fit(data))\n",
    "        StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "        data = scaler.transform(data)\n",
    "   \n",
    "        ## Select Ones\n",
    "        k_ones = np.where(labels == 2)\n",
    "        label_ones = labels[k_ones]\n",
    "        data_ones = data[k_ones]\n",
    "\n",
    "        k_sevens = np.where(labels == 8)\n",
    "        label_sevens = labels[k_sevens]\n",
    "        data_sevens = data[k_sevens]\n",
    "\n",
    "\n",
    "        data_ones = data_ones[220:440] \n",
    "        data_sevens = data_sevens[:11]\n",
    "        # data_sevens =  np.random.uniform(0,1,(len(data_ones),256))\n",
    "        \n",
    "        label_ones      =  1*np.ones(len(data_ones))\n",
    "        label_sevens    =  np.zeros(len(data_sevens))\n",
    "        \n",
    "\n",
    "\n",
    "        return [data_ones,label_ones,data_sevens,label_sevens]\n",
    "    \n",
    "\n",
    "        \n",
    "        data_sevens =  np.random.uniform(0,1,(len(X),256))\n",
    "        label_sevens    =  np.zeros(len(data_sevens))\n",
    "        return [data_sevens,label_sevens]\n",
    "\n",
    "   \n",
    "    def get_TrainingData(self):\n",
    "        \n",
    "        dataPath = './'\n",
    "        import tempfile\n",
    "        import pickle\n",
    "       \n",
    "\n",
    "        with open(dataPath+'usps_data.pkl','rb') as fp:\n",
    "              loaded_data1 = pickle.load(fp, encoding='latin1')\n",
    "\n",
    "        labels = loaded_data1['target']\n",
    "        data = loaded_data1['data']\n",
    "        \n",
    "        ## Scale the data \n",
    "       \n",
    "        print(scaler.fit(data))\n",
    "        StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "        data = scaler.transform(data)\n",
    "   \n",
    "        ## Select Ones\n",
    "        k_ones = np.where(labels == 2)\n",
    "        label_ones = labels[k_ones]\n",
    "        data_ones = data[k_ones]\n",
    "\n",
    "        k_sevens = np.where(labels == 8)\n",
    "        label_sevens = labels[k_sevens]\n",
    "        data_sevens = data[k_sevens]\n",
    "\n",
    "\n",
    "        data_ones = data_ones[:220] \n",
    "        label_ones      =  1*np.ones(len(data_ones))\n",
    "       \n",
    "        return [data_ones,label_ones]\n",
    "    \n",
    "    \n",
    "    def fit(self,X,nu,kernel):\n",
    "  \n",
    "        print(\"Training the OCSVM classifier.....\")\n",
    "        clf = self.train_OCSVM_Classifier(X,nu,kernel)\n",
    "\n",
    "        return clf\n",
    "\n",
    "    \n",
    "    def compute_au_roc(self,y_true, df_score):\n",
    "        y_scores_pos = df_score[0]\n",
    "        y_scores_neg = df_score[1]\n",
    "        y_score = np.concatenate((y_scores_pos, y_scores_neg))\n",
    "        \n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        roc_score = roc_auc_score(y_true, y_score)\n",
    " \n",
    "        return roc_score\n",
    "         \n",
    "         \n",
    "    def predict(self,clf,Xtest_Pos,Xtest_Neg):\n",
    "        decisionScore_POS = clf.decision_function(Xtest_Pos)\n",
    "        decisionScore_Neg = clf.decision_function(Xtest_Neg)\n",
    "        df_score = [ decisionScore_POS, decisionScore_Neg ]\n",
    "        ## y_true\n",
    "        y_true_pos = np.ones(Xtest_Pos.shape[0])\n",
    "        y_true_neg = np.zeros(Xtest_Neg.shape[0])\n",
    "        y_true = np.concatenate((y_true_pos, y_true_neg))\n",
    "        \n",
    "        plt.hist(decisionScore_POS, bins = 25, label = 'Normal');\n",
    "        plt.hist(decisionScore_Neg, bins = 25, label = 'Anomaly');\n",
    "        plt.legend(loc = 'upper right');\n",
    "        plt.title('OC-SVM Normalised Decision Score');\n",
    "\n",
    "        result = self.compute_au_roc(y_true,df_score)\n",
    "        return result\n",
    "        \n",
    "        \n",
    "ocsvm = OCSVM()\n",
    "X_Pos,X_PosLabel = ocsvm.get_TrainingData()\n",
    "[Xtest_Pos,label_ones,Xtest_Neg,label_sevens]= ocsvm.get_TestingData()\n",
    "nu= 0.04\n",
    "kernel = 'rbf'\n",
    "clf = ocsvm.fit(X_Pos,nu,kernel)\n",
    "res = ocsvm.predict(clf,Xtest_Pos,Xtest_Neg)\n",
    "print(\"=\"*35)\n",
    "print(\"AUC:\",res)\n",
    "print(\"=\"*35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OC-NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Training the OCNN classifier.....\n",
      "Training OC-NN started for epochs:  100\n",
      "================================\n",
      "Epoch = 1, r = -566.405496\n",
      "================================\n",
      "Total Cost:  18809752.0\n",
      "Training Time taken, 0.16393804550170898\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -566.4054956054688\n",
      "================================\n",
      "Epoch = 2, r = -565.850132\n",
      "================================\n",
      "Total Cost:  18769572.0\n",
      "Training Time taken, 0.29549384117126465\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -565.8501318359375\n",
      "================================\n",
      "Epoch = 3, r = -565.294673\n",
      "================================\n",
      "Total Cost:  18729436.0\n",
      "Training Time taken, 0.4201350212097168\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -565.2946728515625\n",
      "================================\n",
      "Epoch = 4, r = -564.739231\n",
      "================================\n",
      "Total Cost:  18689348.0\n",
      "Training Time taken, 0.624640941619873\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -564.7392309570313\n",
      "================================\n",
      "Epoch = 5, r = -564.183911\n",
      "================================\n",
      "Total Cost:  18649310.0\n",
      "Training Time taken, 0.764732837677002\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -564.1839111328125\n",
      "================================\n",
      "Epoch = 6, r = -563.628699\n",
      "================================\n",
      "Total Cost:  18609318.0\n",
      "Training Time taken, 0.9200749397277832\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -563.6286987304687\n",
      "================================\n",
      "Epoch = 7, r = -563.073423\n",
      "================================\n",
      "Total Cost:  18569374.0\n",
      "Training Time taken, 1.0844550132751465\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -563.0734228515626\n",
      "================================\n",
      "Epoch = 8, r = -562.518223\n",
      "================================\n",
      "Total Cost:  18529482.0\n",
      "Training Time taken, 1.264901876449585\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -562.5182226562499\n",
      "================================\n",
      "Epoch = 9, r = -561.963223\n",
      "================================\n",
      "Total Cost:  18489644.0\n",
      "Training Time taken, 1.4560859203338623\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -561.96322265625\n",
      "================================\n",
      "Epoch = 10, r = -561.422817\n",
      "================================\n",
      "Total Cost:  18449850.0\n",
      "Training Time taken, 1.667151927947998\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -561.4228173828125\n",
      "================================\n",
      "Epoch = 11, r = -560.890002\n",
      "================================\n",
      "Total Cost:  18410110.0\n",
      "Training Time taken, 1.8889620304107666\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -560.8900024414063\n",
      "================================\n",
      "Epoch = 12, r = -560.357217\n",
      "================================\n",
      "Total Cost:  18370422.0\n",
      "Training Time taken, 2.1279098987579346\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -560.357216796875\n",
      "================================\n",
      "Epoch = 13, r = -559.824661\n",
      "================================\n",
      "Total Cost:  18330788.0\n",
      "Training Time taken, 2.377565860748291\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -559.8246606445313\n",
      "================================\n",
      "Epoch = 14, r = -559.292102\n",
      "================================\n",
      "Total Cost:  18291210.0\n",
      "Training Time taken, 2.6493871212005615\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -559.2921020507813\n",
      "================================\n",
      "Epoch = 15, r = -558.759758\n",
      "================================\n",
      "Total Cost:  18251682.0\n",
      "Training Time taken, 2.935703754425049\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -558.7597583007812\n",
      "================================\n",
      "Epoch = 16, r = -558.227505\n",
      "================================\n",
      "Total Cost:  18212212.0\n",
      "Training Time taken, 3.2362849712371826\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -558.2275048828125\n",
      "================================\n",
      "Epoch = 17, r = -557.695342\n",
      "================================\n",
      "Total Cost:  18172798.0\n",
      "Training Time taken, 3.550341844558716\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -557.695341796875\n",
      "================================\n",
      "Epoch = 18, r = -557.163330\n",
      "================================\n",
      "Total Cost:  18133436.0\n",
      "Training Time taken, 3.878415822982788\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -557.163330078125\n",
      "================================\n",
      "Epoch = 19, r = -556.631440\n",
      "================================\n",
      "Total Cost:  18094136.0\n",
      "Training Time taken, 4.214514970779419\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -556.6314404296875\n",
      "================================\n",
      "Epoch = 20, r = -556.099717\n",
      "================================\n",
      "Total Cost:  18054890.0\n",
      "Training Time taken, 4.561079740524292\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -556.099716796875\n",
      "================================\n",
      "Epoch = 21, r = -555.568130\n",
      "================================\n",
      "Total Cost:  18015700.0\n",
      "Training Time taken, 4.9219090938568115\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -555.5681298828125\n",
      "================================\n",
      "Epoch = 22, r = -555.017063\n",
      "================================\n",
      "Total Cost:  17976570.0\n",
      "Training Time taken, 5.302932024002075\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -555.0170629882813\n",
      "================================\n",
      "Epoch = 23, r = -554.416191\n",
      "================================\n",
      "Total Cost:  17937496.0\n",
      "Training Time taken, 5.69983696937561\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -554.4161914062499\n",
      "================================\n",
      "Epoch = 24, r = -553.815457\n",
      "================================\n",
      "Total Cost:  17898484.0\n",
      "Training Time taken, 6.109378814697266\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -553.8154565429688\n",
      "================================\n",
      "Epoch = 25, r = -553.215076\n",
      "================================\n",
      "Total Cost:  17859530.0\n",
      "Training Time taken, 6.524207830429077\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -553.2150756835938\n",
      "================================\n",
      "Epoch = 26, r = -552.683716\n",
      "================================\n",
      "Total Cost:  17820634.0\n",
      "Training Time taken, 6.9597320556640625\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -552.6837158203125\n",
      "================================\n",
      "Epoch = 27, r = -552.163362\n",
      "================================\n",
      "Total Cost:  17781800.0\n",
      "Training Time taken, 7.409555912017822\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -552.1633618164062\n",
      "================================\n",
      "Epoch = 28, r = -551.643147\n",
      "================================\n",
      "Total Cost:  17743024.0\n",
      "Training Time taken, 7.868250846862793\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -551.6431469726563\n",
      "================================\n",
      "Epoch = 29, r = -551.123147\n",
      "================================\n",
      "Total Cost:  17704310.0\n",
      "Training Time taken, 8.347241878509521\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -551.1231469726563\n",
      "================================\n",
      "Epoch = 30, r = -550.603252\n",
      "================================\n",
      "Total Cost:  17665656.0\n",
      "Training Time taken, 8.832917928695679\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -550.603251953125\n",
      "================================\n",
      "Epoch = 31, r = -550.083633\n",
      "================================\n",
      "Total Cost:  17627060.0\n",
      "Training Time taken, 9.336359024047852\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -550.0836328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Epoch = 32, r = -549.564211\n",
      "================================\n",
      "Total Cost:  17588528.0\n",
      "Training Time taken, 9.851768732070923\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -549.5642114257812\n",
      "================================\n",
      "Epoch = 33, r = -549.044961\n",
      "================================\n",
      "Total Cost:  17550060.0\n",
      "Training Time taken, 10.380896091461182\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -549.0449609375\n",
      "================================\n",
      "Epoch = 34, r = -548.525891\n",
      "================================\n",
      "Total Cost:  17511650.0\n",
      "Training Time taken, 10.928784847259521\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -548.5258911132812\n",
      "================================\n",
      "Epoch = 35, r = -548.006990\n",
      "================================\n",
      "Total Cost:  17473300.0\n",
      "Training Time taken, 11.49016785621643\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -548.0069897460937\n",
      "================================\n",
      "Epoch = 36, r = -547.488333\n",
      "================================\n",
      "Total Cost:  17435014.0\n",
      "Training Time taken, 12.063787937164307\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -547.4883325195312\n",
      "================================\n",
      "Epoch = 37, r = -546.969922\n",
      "================================\n",
      "Total Cost:  17396792.0\n",
      "Training Time taken, 12.648945808410645\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -546.969921875\n",
      "================================\n",
      "Epoch = 38, r = -546.451648\n",
      "================================\n",
      "Total Cost:  17358630.0\n",
      "Training Time taken, 13.256454944610596\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -546.4516479492188\n",
      "================================\n",
      "Epoch = 39, r = -545.933586\n",
      "================================\n",
      "Total Cost:  17320530.0\n",
      "Training Time taken, 13.937816858291626\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -545.9335864257813\n",
      "================================\n",
      "Epoch = 40, r = -545.415801\n",
      "================================\n",
      "Total Cost:  17282492.0\n",
      "Training Time taken, 14.57033395767212\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -545.41580078125\n",
      "================================\n",
      "Epoch = 41, r = -544.898108\n",
      "================================\n",
      "Total Cost:  17244520.0\n",
      "Training Time taken, 15.231745958328247\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -544.8981079101562\n",
      "================================\n",
      "Epoch = 42, r = -544.380674\n",
      "================================\n",
      "Total Cost:  17206608.0\n",
      "Training Time taken, 15.895879983901978\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -544.380673828125\n",
      "================================\n",
      "Epoch = 43, r = -543.863530\n",
      "================================\n",
      "Total Cost:  17168756.0\n",
      "Training Time taken, 16.578857898712158\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -543.8635302734375\n",
      "================================\n",
      "Epoch = 44, r = -543.346509\n",
      "================================\n",
      "Total Cost:  17130970.0\n",
      "Training Time taken, 17.27918004989624\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -543.3465087890625\n",
      "================================\n",
      "Epoch = 45, r = -542.829731\n",
      "================================\n",
      "Total Cost:  17093250.0\n",
      "Training Time taken, 17.99746584892273\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -542.8297314453125\n",
      "================================\n",
      "Epoch = 46, r = -542.313169\n",
      "================================\n",
      "Total Cost:  17055588.0\n",
      "Training Time taken, 18.73904275894165\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -542.3131689453126\n",
      "================================\n",
      "Epoch = 47, r = -541.796912\n",
      "================================\n",
      "Total Cost:  17017988.0\n",
      "Training Time taken, 19.503005027770996\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -541.7969116210937\n",
      "================================\n",
      "Epoch = 48, r = -541.280718\n",
      "================================\n",
      "Total Cost:  16980456.0\n",
      "Training Time taken, 20.272783756256104\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -541.2807177734375\n",
      "================================\n",
      "Epoch = 49, r = -540.764902\n",
      "================================\n",
      "Total Cost:  16942982.0\n",
      "Training Time taken, 21.057066917419434\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -540.76490234375\n",
      "================================\n",
      "Epoch = 50, r = -540.249194\n",
      "================================\n",
      "Total Cost:  16905574.0\n",
      "Training Time taken, 21.849381923675537\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -540.2491943359375\n",
      "================================\n",
      "Epoch = 51, r = -539.733733\n",
      "================================\n",
      "Total Cost:  16868228.0\n",
      "Training Time taken, 22.651970863342285\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -539.7337329101563\n",
      "================================\n",
      "Epoch = 52, r = -539.218560\n",
      "================================\n",
      "Total Cost:  16830944.0\n",
      "Training Time taken, 23.47978973388672\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -539.2185595703124\n",
      "================================\n",
      "Epoch = 53, r = -538.703525\n",
      "================================\n",
      "Total Cost:  16793724.0\n",
      "Training Time taken, 24.32606792449951\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -538.703525390625\n",
      "================================\n",
      "Epoch = 54, r = -538.188796\n",
      "================================\n",
      "Total Cost:  16756568.0\n",
      "Training Time taken, 25.17937207221985\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -538.1887963867188\n",
      "================================\n",
      "Epoch = 55, r = -537.674236\n",
      "================================\n",
      "Total Cost:  16719473.0\n",
      "Training Time taken, 26.045188903808594\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -537.6742358398437\n",
      "================================\n",
      "Epoch = 56, r = -537.159949\n",
      "================================\n",
      "Total Cost:  16682442.0\n",
      "Training Time taken, 26.90643310546875\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -537.1599487304687\n",
      "================================\n",
      "Epoch = 57, r = -536.645847\n",
      "================================\n",
      "Total Cost:  16645475.0\n",
      "Training Time taken, 27.800585985183716\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -536.6458471679688\n",
      "================================\n",
      "Epoch = 58, r = -536.131973\n",
      "================================\n",
      "Total Cost:  16608569.0\n",
      "Training Time taken, 28.720096111297607\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -536.13197265625\n",
      "================================\n",
      "Epoch = 59, r = -535.618330\n",
      "================================\n",
      "Total Cost:  16571727.0\n",
      "Training Time taken, 29.669830799102783\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -535.618330078125\n",
      "================================\n",
      "Epoch = 60, r = -535.104915\n",
      "================================\n",
      "Total Cost:  16534948.0\n",
      "Training Time taken, 30.600116968154907\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -535.1049145507812\n",
      "================================\n",
      "Epoch = 61, r = -534.591775\n",
      "================================\n",
      "Total Cost:  16498231.0\n",
      "Training Time taken, 31.53644895553589\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -534.5917749023438\n",
      "================================\n",
      "Epoch = 62, r = -534.078804\n",
      "================================\n",
      "Total Cost:  16461577.0\n",
      "Training Time taken, 32.48229789733887\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -534.0788037109376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Epoch = 63, r = -533.566121\n",
      "================================\n",
      "Total Cost:  16424986.0\n",
      "Training Time taken, 33.45150184631348\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -533.5661206054688\n",
      "================================\n",
      "Epoch = 64, r = -533.053594\n",
      "================================\n",
      "Total Cost:  16388457.0\n",
      "Training Time taken, 34.45104002952576\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -533.05359375\n",
      "================================\n",
      "Epoch = 65, r = -532.541401\n",
      "================================\n",
      "Total Cost:  16351990.0\n",
      "Training Time taken, 35.45442485809326\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -532.5414013671875\n",
      "================================\n",
      "Epoch = 66, r = -532.029331\n",
      "================================\n",
      "Total Cost:  16315586.0\n",
      "Training Time taken, 36.47979283332825\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -532.0293310546875\n",
      "================================\n",
      "Epoch = 67, r = -531.517537\n",
      "================================\n",
      "Total Cost:  16279247.0\n",
      "Training Time taken, 37.50884199142456\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -531.5175366210938\n",
      "================================\n",
      "Epoch = 68, r = -531.006033\n",
      "================================\n",
      "Total Cost:  16242969.0\n",
      "Training Time taken, 38.54046177864075\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -531.0060327148437\n",
      "================================\n",
      "Epoch = 69, r = -530.494680\n",
      "================================\n",
      "Total Cost:  16206754.0\n",
      "Training Time taken, 39.58052206039429\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -530.4946801757812\n",
      "================================\n",
      "Epoch = 70, r = -529.983604\n",
      "================================\n",
      "Total Cost:  16170601.0\n",
      "Training Time taken, 40.66517496109009\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -529.983603515625\n",
      "================================\n",
      "Epoch = 71, r = -529.472725\n",
      "================================\n",
      "Total Cost:  16134509.0\n",
      "Training Time taken, 41.78107976913452\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -529.4727246093751\n",
      "================================\n",
      "Epoch = 72, r = -528.962078\n",
      "================================\n",
      "Total Cost:  16098482.0\n",
      "Training Time taken, 42.95961403846741\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -528.9620776367187\n",
      "================================\n",
      "Epoch = 73, r = -528.451719\n",
      "================================\n",
      "Total Cost:  16062515.0\n",
      "Training Time taken, 44.08746910095215\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -528.45171875\n",
      "================================\n",
      "Epoch = 74, r = -527.941514\n",
      "================================\n",
      "Total Cost:  16026612.0\n",
      "Training Time taken, 45.21251583099365\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -527.941513671875\n",
      "================================\n",
      "Epoch = 75, r = -527.431536\n",
      "================================\n",
      "Total Cost:  15990769.0\n",
      "Training Time taken, 46.3586208820343\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -527.4315356445313\n",
      "================================\n",
      "Epoch = 76, r = -526.921836\n",
      "================================\n",
      "Total Cost:  15954990.0\n",
      "Training Time taken, 47.521636962890625\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -526.9218359375\n",
      "================================\n",
      "Epoch = 77, r = -526.412424\n",
      "================================\n",
      "Total Cost:  15919272.0\n",
      "Training Time taken, 48.67883896827698\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -526.4124243164063\n",
      "================================\n",
      "Epoch = 78, r = -525.903120\n",
      "================================\n",
      "Total Cost:  15883615.0\n",
      "Training Time taken, 49.89573574066162\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -525.9031201171875\n",
      "================================\n",
      "Epoch = 79, r = -525.394167\n",
      "================================\n",
      "Total Cost:  15848021.0\n",
      "Training Time taken, 51.113425970077515\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -525.3941674804687\n",
      "================================\n",
      "Epoch = 80, r = -524.885383\n",
      "================================\n",
      "Total Cost:  15812490.0\n",
      "Training Time taken, 52.338162899017334\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -524.8853833007812\n",
      "================================\n",
      "Epoch = 81, r = -524.376890\n",
      "================================\n",
      "Total Cost:  15777017.0\n",
      "Training Time taken, 53.5727219581604\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -524.3768896484374\n",
      "================================\n",
      "Epoch = 82, r = -523.868579\n",
      "================================\n",
      "Total Cost:  15741611.0\n",
      "Training Time taken, 54.84564471244812\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -523.8685791015625\n",
      "================================\n",
      "Epoch = 83, r = -523.360420\n",
      "================================\n",
      "Total Cost:  15706264.0\n",
      "Training Time taken, 56.107324838638306\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -523.3604199218751\n",
      "================================\n",
      "Epoch = 84, r = -522.852722\n",
      "================================\n",
      "Total Cost:  15670977.0\n",
      "Training Time taken, 57.38811707496643\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -522.8527221679688\n",
      "================================\n",
      "Epoch = 85, r = -522.345068\n",
      "================================\n",
      "Total Cost:  15635755.0\n",
      "Training Time taken, 58.65109896659851\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -522.3450683593751\n",
      "================================\n",
      "Epoch = 86, r = -521.837644\n",
      "================================\n",
      "Total Cost:  15600592.0\n",
      "Training Time taken, 59.953410148620605\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -521.8376440429688\n",
      "================================\n",
      "Epoch = 87, r = -521.330586\n",
      "================================\n",
      "Total Cost:  15565489.0\n",
      "Training Time taken, 61.285388708114624\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -521.3305859375\n",
      "================================\n",
      "Epoch = 88, r = -520.823667\n",
      "================================\n",
      "Total Cost:  15530449.0\n",
      "Training Time taken, 62.62309694290161\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -520.8236669921874\n",
      "================================\n",
      "Epoch = 89, r = -520.317007\n",
      "================================\n",
      "Total Cost:  15495472.0\n",
      "Training Time taken, 63.98725986480713\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -520.3170068359375\n",
      "================================\n",
      "Epoch = 90, r = -519.810637\n",
      "================================\n",
      "Total Cost:  15460553.0\n",
      "Training Time taken, 65.35750889778137\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -519.8106372070313\n",
      "================================\n",
      "Epoch = 91, r = -519.304390\n",
      "================================\n",
      "Total Cost:  15425696.0\n",
      "Training Time taken, 66.75428295135498\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -519.3043896484374\n",
      "================================\n",
      "Epoch = 92, r = -518.798401\n",
      "================================\n",
      "Total Cost:  15390903.0\n",
      "Training Time taken, 68.17244386672974\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -518.7984008789062\n",
      "================================\n",
      "Epoch = 93, r = -518.292749\n",
      "================================\n",
      "Total Cost:  15356168.0\n",
      "Training Time taken, 69.60111379623413\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -518.2927490234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Epoch = 94, r = -517.787144\n",
      "================================\n",
      "Total Cost:  15321494.0\n",
      "Training Time taken, 71.03477883338928\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -517.7871435546875\n",
      "================================\n",
      "Epoch = 95, r = -517.281921\n",
      "================================\n",
      "Total Cost:  15286882.0\n",
      "Training Time taken, 72.4784209728241\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -517.2819213867188\n",
      "================================\n",
      "Epoch = 96, r = -516.776912\n",
      "================================\n",
      "Total Cost:  15252331.0\n",
      "Training Time taken, 73.92968606948853\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -516.7769116210937\n",
      "================================\n",
      "Epoch = 97, r = -516.272085\n",
      "================================\n",
      "Total Cost:  15217839.0\n",
      "Training Time taken, 75.4186360836029\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -516.2720849609375\n",
      "================================\n",
      "Epoch = 98, r = -515.767549\n",
      "================================\n",
      "Total Cost:  15183410.0\n",
      "Training Time taken, 76.90238904953003\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -515.767548828125\n",
      "================================\n",
      "Epoch = 99, r = -515.263257\n",
      "================================\n",
      "Total Cost:  15149040.0\n",
      "Training Time taken, 78.39984393119812\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -515.2632568359375\n",
      "================================\n",
      "Epoch = 100, r = -514.759180\n",
      "================================\n",
      "Total Cost:  15114729.0\n",
      "Training Time taken, 79.91944408416748\n",
      "Saving the trained Model weights ... @ ./model_weights/\n",
      "The optimized value of r found is -514.7591796875\n",
      "===================================\n",
      "AUC: 0.3504132231404959\n",
      "===================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class OCNN:\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import numpy  as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as srn\n",
    "  \n",
    "    \n",
    "\n",
    "    results = \"./sanity_results/\"\n",
    "    decision_scorePath = \"./scores/\"\n",
    "    df_usps_scores  = {}\n",
    "    activations = [\"Linear\",\"Sigmoid\"]\n",
    "    methods = [\"Linear\",\"RBF\"]\n",
    "    path = \"./scores/\"\n",
    "    model_weights = \"./model_weights/\"\n",
    "   \n",
    "    nu = 0.1\n",
    "    scaler = StandardScaler()\n",
    "    h_size = 200\n",
    "    \n",
    "\n",
    "    def write_Scores2Csv(self,train, trainscore, test, testscore,filename):\n",
    "\n",
    "            data = np.concatenate((train, test))\n",
    "            score= np.concatenate((trainscore,testscore))\n",
    "            data = data.tolist()\n",
    "            score = score.tolist()\n",
    "            with open(filename, 'a') as myfile:\n",
    "                wr = csv.writer(myfile)\n",
    "                wr.writerow((\"x\", \"score\"))\n",
    "            for row in range(0,len(data)):\n",
    "                with open(filename,\n",
    "                        'a') as myfile:\n",
    "                    wr = csv.writer(myfile)\n",
    "\n",
    "                    wr.writerow((\" \".join(str(x) for x in data[row]), \" \".join(str(x) for x in score[row])))\n",
    "    def write_decisionScores2Csv(self,path, filename, positiveScores, negativeScores):\n",
    "\n",
    "            newfilePath = path+filename\n",
    "            print(\"Writing file to \", path+filename)\n",
    "            poslist = positiveScores.tolist()\n",
    "            neglist = negativeScores.tolist()\n",
    "\n",
    "            # rows = zip(poslist, neglist)\n",
    "            d = [poslist, neglist]\n",
    "            export_data = izip_longest(*d, fillvalue='')\n",
    "            with open(newfilePath, 'w') as myfile:\n",
    "                wr = csv.writer(myfile)\n",
    "                wr.writerow((\"Normal\", \"Anomaly\"))\n",
    "                wr.writerows(export_data)\n",
    "            myfile.close()\n",
    "\n",
    "            return\n",
    "\n",
    "    def train_OCNN_Classifier(self,X_train,nu,activation,epochs):\n",
    "\n",
    "        RANDOM_SEED = 42\n",
    "        tf.reset_default_graph()\n",
    "        train_X = X_train\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "        outfile = \"./model_weights/\"\n",
    "        oCSVMweights = \"./weights/\"\n",
    "        import time\n",
    "\n",
    "        # Layer's sizes\n",
    "        x_size = train_X.shape[1]   # Number of input nodes: 4 features and 1 bias\n",
    "        h_size = self.h_size             # Number of hidden nodes\n",
    "        y_size = 1   # Number of outcomes (3 iris flowers)\n",
    "        D = x_size\n",
    "        K = h_size\n",
    "        theta = np.random.normal(0, 1, K + K*D + 1)\n",
    "        rvalue = np.random.normal(0,1,(len(train_X),y_size))\n",
    "        g   = lambda x : (1/np.sqrt(h_size) )*tf.cos(x/0.02)\n",
    "\n",
    "        def init_weights(shape):\n",
    "            \"\"\" Weight initialization \"\"\"\n",
    "            weights = tf.random_normal(shape,mean=0, stddev=0.5)\n",
    "            return tf.Variable(weights,trainable=False)\n",
    "\n",
    "            def forwardprop(X, w_1, w_2):\n",
    "                \"\"\"\n",
    "                Forward-propagation.\n",
    "                IMPORTANT: yhat is not softmax since TensorFlow's softmax_cross_entropy_with_logits() does that internally.\n",
    "                \"\"\"\n",
    "                X = tf.cast(X, tf.float32)\n",
    "                w_1 = tf.cast(w_1, tf.float32)\n",
    "                w_2 = tf.cast(w_2, tf.float32)\n",
    "                h    = tf.nn.sigmoid(tf.matmul(X, w_1))  # The \\sigma function\n",
    "                yhat = tf.matmul(h, w_2)  # The \\varphi function\n",
    "                return yhat\n",
    "        \n",
    "      \n",
    "        \n",
    "        def nnScore(X, w, V, g,bias1,bias2):\n",
    "            X = tf.cast(X, tf.float32)\n",
    "            w = tf.cast(w, tf.float32)\n",
    "            V = tf.cast(V, tf.float32)\n",
    "            y_hat =tf.matmul(g((tf.matmul(X, w)+bias1)), V) +bias2\n",
    "\n",
    "            return y_hat\n",
    "        \n",
    "        def relu(x):\n",
    "            y = x\n",
    "            y[y < 0] = 0\n",
    "            return y\n",
    "        \n",
    "        # For testing the algorithm\n",
    "        def compute_LossValue(X, nu, w1, w2, g, r,bias1,bias2):\n",
    "            w = w1\n",
    "            V = w2\n",
    "\n",
    "            X = tf.cast(X, tf.float32)\n",
    "            w = tf.cast(w1, tf.float32)\n",
    "            V = tf.cast(w2, tf.float32)\n",
    "            term1 = 0.5 * tf.reduce_sum(tf.square(w))\n",
    "            term2 = 0.5 * tf.reduce_sum(tf.square(V))\n",
    "\n",
    "\n",
    "            \n",
    "            term3 = 1 / nu * tf.reduce_mean(tf.nn.relu(r - nnScore(X, w, V, g,bias1,bias2)))\n",
    "            term4 = -r\n",
    "            \n",
    "            y_hat = nnScore(X, w, V, g,bias1,bias2)\n",
    "            \n",
    "            totalCost = term1 + term2 + term3 + term4\n",
    "                \n",
    "            loss=   [term1,term2,term3,term4,totalCost,y_hat]\n",
    "            \n",
    "            return loss\n",
    "            \n",
    "            \n",
    "        def ocnn_obj(theta, X, nu, w1, w2, g,r,bias1,bias2):\n",
    "\n",
    "            w = w1\n",
    "            V = w2\n",
    "     \n",
    "            X = tf.cast(X, tf.float32)\n",
    "            w = tf.cast(w1, tf.float32)\n",
    "            V = tf.cast(w2, tf.float32)\n",
    "\n",
    "\n",
    "            term1 = 0.5  * tf.reduce_sum(w**2)\n",
    "            term2 = 0.5  * tf.reduce_sum(V**2)\n",
    "            term3 = 1/nu * tf.reduce_mean(tf.nn.relu(r - nnScore(X, w, V, g,bias1,bias2)))\n",
    "            term4 = -r\n",
    "\n",
    "            return term1 + term2 + term3 + term4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Symbols\n",
    "        X = tf.placeholder(\"float32\", shape=[None, x_size])\n",
    "\n",
    "        r = tf.get_variable(\"r\", dtype=tf.float32,shape=())\n",
    "\n",
    "        # Weight initializations\n",
    "        w_1 = init_weights((x_size, h_size))\n",
    "           \n",
    "        weights = tf.random_normal((h_size, y_size),mean=0, stddev=0.1)\n",
    "           \n",
    "        ocsvm_wt = np.load(oCSVMweights+\"ocsvm_wt.npy\")\n",
    "        w_2 =tf.get_variable(\"tf_var_initialized_ocsvm\",\n",
    "                                initializer=ocsvm_wt)\n",
    "            \n",
    "        bias1 = tf.Variable(initial_value=[[1.0]], dtype=tf.float32,trainable=False)\n",
    "        bias2 = tf.Variable(initial_value=[[0.0]], dtype=tf.float32,trainable=False)\n",
    "\n",
    "\n",
    "        cost    = ocnn_obj(theta, X, nu, w_1, w_2, g,r,bias1,bias2)\n",
    "        #updates = tf.train.GradientDescentOptimizer(0.0001).minimize(cost)\n",
    "        updates = tf.train.AdamOptimizer(4.7 * 1e-1).minimize(cost)\n",
    "\n",
    "        # Run SGD\n",
    "        sess = tf.Session()\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        rvalue = 0.1\n",
    "        start_time = time.time()\n",
    "        print(\"Training OC-NN started for epochs: \",epochs)\n",
    "        for epoch in range(epochs):\n",
    "                    # Train with each example\n",
    "            sess.run(updates, feed_dict={X: train_X})\n",
    "                        \n",
    "                    \n",
    "            with sess.as_default():\n",
    "                svalue = nnScore(train_X, w_1, w_2, g,bias1,bias2)  \n",
    "                rval = svalue.eval()\n",
    "                rvalue = np.percentile(rval,q=100*nu)\n",
    "                            \n",
    "\n",
    "                costvalue = compute_LossValue(train_X, nu, w_1, w_2, g, rvalue,bias1,bias2)\n",
    "                term1 = costvalue[0].eval()\n",
    "                term2 = costvalue[1].eval()\n",
    "                term3 = costvalue[2].eval()\n",
    "                term4 = costvalue[3]\n",
    "                term5 = costvalue[4].eval()\n",
    "                yval = costvalue[5].eval()\n",
    "                print (\"================================\")\n",
    "                print (\"Epoch = %d, r = %f\"\n",
    "                        % (epoch + 1,rvalue))\n",
    "                print (\"================================\")\n",
    "                print (\"Total Cost: \",np.mean(term5))\n",
    "                        \n",
    "                import time\n",
    "                trainTime = time.time() - start_time\n",
    "                print(\"Training Time taken,\",trainTime)\n",
    "          \n",
    "            \n",
    "            \n",
    "                with sess.as_default():\n",
    "                    np_w_1= w_1.eval()\n",
    "                    np_w_2= w_2.eval()\n",
    "                    np_bias1= bias1.eval()\n",
    "                    np_bias2= bias2.eval()\n",
    "            \n",
    "                rstar =rvalue\n",
    "#             sess.close()\n",
    "#             print(\"Session Closed!!!\")\n",
    "\n",
    "            # save the w_1 and bias1 to numpy array\n",
    "            print(\"Saving the trained Model weights ... @\",outfile)\n",
    "            print(\"The optimized value of r found is\",rstar)\n",
    "            np.save(outfile+\"w_1\", np_w_1)\n",
    "            np.save(outfile+\"w_2\", np_w_2)\n",
    "            np.save(outfile+\"bias1\",np_bias1)\n",
    "            np.save(outfile+\"bias2\",np_bias2)\n",
    "\n",
    "   \n",
    "    def get_TestingData(self):\n",
    "\n",
    "        dataPath = './'\n",
    "        import tempfile\n",
    "        import pickle\n",
    "\n",
    "        with open(dataPath+'usps_data.pkl','rb') as fp:\n",
    "              loaded_data1 = pickle.load(fp, encoding='latin1')\n",
    "\n",
    "        labels = loaded_data1['target']\n",
    "        data = loaded_data1['data']\n",
    "        \n",
    "        ## Scale the data \n",
    "       \n",
    "  \n",
    "        print(scaler.fit(data))\n",
    "        StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "        data = scaler.transform(data)\n",
    "   \n",
    "        ## Select Ones\n",
    "        k_ones = np.where(labels == 2)\n",
    "        label_ones = labels[k_ones]\n",
    "        data_ones = data[k_ones]\n",
    "\n",
    "        k_sevens = np.where(labels == 8)\n",
    "        label_sevens = labels[k_sevens]\n",
    "        data_sevens = data[k_sevens]\n",
    "\n",
    "\n",
    "        data_ones = data_ones[220:440] \n",
    "        data_sevens = data_sevens[0:11]\n",
    "        # data_sevens =  np.random.uniform(0,1,(len(data_ones),256))\n",
    "        \n",
    "        label_ones      =  1*np.ones(len(data_ones))\n",
    "        label_sevens    =  np.zeros(len(data_sevens))\n",
    "        \n",
    "\n",
    "\n",
    "        return [data_ones,label_ones,data_sevens,label_sevens]\n",
    "    \n",
    "\n",
    "        \n",
    "        data_sevens =  np.random.uniform(0,1,(len(X),256))\n",
    "        label_sevens    =  np.zeros(len(data_sevens))\n",
    "        return [data_sevens,label_sevens]\n",
    "  \n",
    "    def get_TrainingData(self):\n",
    "        \n",
    "        dataPath = './'\n",
    "        import tempfile\n",
    "        import pickle\n",
    "       \n",
    "\n",
    "        with open(dataPath+'usps_data.pkl','rb') as fp:\n",
    "              loaded_data1 = pickle.load(fp, encoding='latin1')\n",
    "\n",
    "        labels = loaded_data1['target']\n",
    "        data = loaded_data1['data']\n",
    "        \n",
    "        ## Scale the data \n",
    "       \n",
    "        print(scaler.fit(data))\n",
    "        StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "        data = scaler.transform(data)\n",
    "   \n",
    "        ## Select Ones\n",
    "        k_ones = np.where(labels == 2)\n",
    "        label_ones = labels[k_ones]\n",
    "        data_ones = data[k_ones]\n",
    "\n",
    "        k_sevens = np.where(labels == 8)\n",
    "        label_sevens = labels[k_sevens]\n",
    "        data_sevens = data[k_sevens]\n",
    "\n",
    "\n",
    "        data_ones = data_ones[:220] \n",
    "        label_ones      =  1*np.ones(len(data_ones))\n",
    "       \n",
    "        return [data_ones,label_ones]\n",
    "     \n",
    "    def fit(self,X,nu,activation,epochs):\n",
    "  \n",
    "        print(\"Training the OCNN classifier.....\")\n",
    "        self.train_OCNN_Classifier(X,nu,activation,epochs)\n",
    "\n",
    "        return   \n",
    "    \n",
    "    def compute_au_roc(self,y_true, df_score):\n",
    "        y_scores_pos = df_score[0]\n",
    "        y_scores_neg = df_score[1]\n",
    "        y_score = np.concatenate((y_scores_pos, y_scores_neg))\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        roc_score = roc_auc_score(y_true, y_score)\n",
    " \n",
    "        return roc_score\n",
    "    \n",
    "    def decision_function(self,X, w_1, w_2, g,bias1,bias2):   \n",
    "        score =np.matmul(g((np.matmul(X, w_1)+bias1)), w_2) +bias2\n",
    "        return score\n",
    "\n",
    "    def predict(self,Xtest_Pos,Xtest_Neg):\n",
    "        \n",
    "        ## Load the saved model and compute the decision score\n",
    "        model_weights = \"./model_weights/\"\n",
    "        w_1 = np.load(model_weights+\"/w_1.npy\")\n",
    "        w_2 = np.load(model_weights+\"/w_2.npy\")\n",
    "        bias1 = np.load(model_weights+\"/bias1.npy\")\n",
    "        bias2 = np.load(model_weights+\"/bias2.npy\")\n",
    "        \n",
    "        \n",
    "        g   = lambda x : (1/np.sqrt(self.h_size) )*np.cos(x/0.02)\n",
    "\n",
    "        decisionScore_POS= self.decision_function(Xtest_Pos, w_1, w_2, g,bias1,bias2)\n",
    "        decisionScore_Neg = self.decision_function(Xtest_Neg, w_1, w_2, g,bias1,bias2)\n",
    "   \n",
    "        df_score = [decisionScore_POS, decisionScore_Neg]\n",
    "        \n",
    "        ## y_true\n",
    "        y_true_pos = np.ones(Xtest_Pos.shape[0])\n",
    "        y_true_neg = np.zeros(Xtest_Neg.shape[0])\n",
    "        y_true = np.concatenate((y_true_pos, y_true_neg))\n",
    "\n",
    "        plt.hist(decisionScore_POS, bins = 25, label = 'Normal')\n",
    "        plt.hist(decisionScore_Neg, bins = 25, label = 'Anomaly')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        plt.title('OC-NN Normalised Decision Score')\n",
    "\n",
    "        result = self.compute_au_roc(y_true,df_score)\n",
    "        return result\n",
    "        \n",
    "\n",
    "\n",
    "## Instantiate the object and call the function\n",
    "ocnn = OCNN()\n",
    "X_Pos,X_PosLabel = ocnn.get_TrainingData()\n",
    "[Xtest_Pos,label_ones,Xtest_Neg,label_sevens]= ocnn.get_TestingData()\n",
    "nu= 0.04\n",
    "activation = 'sigmoid'\n",
    "epochs = 100\n",
    "ocnn.fit(X_Pos,nu,activation,epochs)\n",
    "res = ocnn.predict(Xtest_Pos,Xtest_Neg)\n",
    "print(\"=\"*35)\n",
    "print(\"AUC:\",res)\n",
    "print(\"=\"*35)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
